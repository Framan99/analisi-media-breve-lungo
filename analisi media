import pandas as pd
import numpy as np
import pandas as pd
import numpy as np

%matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt

data_num = pd.read_csv("Goals.csv", sep = ';', index_col=0)
columns = data.columns
data_num= pd.read_csv("Goal_numerical_values.csv", sep = ';', header=0)
columns_num = data_num.columns
errore_breve = data_num['Media (Feb - Plan)'] - data_num['Media (Feb - Real)']
errore_breve
errore_breve.describe()
media_breve = errore_breve.mean()
media_breve = errore_breve - media_breve
media_breve = pd.DataFrame(media_breve.transpose(), columns = ['media_breve'])
media_breve = media_breve.fillna(0)
hist = errore_breve.hist()
errore_lungo_set_max = data_num['Media Max'] - data_num['Media (Set)']
errore_lungo_set_max.mean()
errore_lungo_set_min = data_num['Media min'] - data_num['Media (Set)']
errore_lungo_set_min.mean()
errore_lungo_lug_max = data_num['Media Max'] - data_num['Media (lug)']
errore_lungo_lug_max.mean()
errore_lungo_lug_min = data_num['Media min'] - data_num['Media (lug)']
errore_lungo_lug_min.mean()
variazione_media_lug_min = errore_breve - errore_lungo_lug_min
variazione_media_lug_min
variazione_media_lug_max = errore_breve - errore_lungo_lug_max
variazione_media_lug_max
variazione_media_lug = variazione_media_lug_max - variazione_media_lug_min
variazione_media_lug
variazione_media_set_min = errore_breve - errore_lungo_set_min
variazione_media_set_min
variazione_media_set_max = errore_breve - errore_lungo_set_max
variazione_media_set_max
variazione_media_set_min = errore_breve - errore_lungo_set_min
variazione_media_set_min
variazione_media_set_max = errore_breve - errore_lungo_set_max
variazione_media_set_max
variazione_media_set = variazione_media_set_max - variazione_media_set_min
variazione_media_set
comparazione = [errore_breve, variazione_media_lug, variazione_media_set]
comparazione = pd.DataFrame(comparazione).transpose()
comparazione = comparazione.fillna(0)
comparazione.columns = ['errore_breve','variazione_media_lug', 'variazione_media_set']
comparazione = comparazione.fillna(0)
comparazione
comparazione.mean()
hist = comparazione.hist()
comparazione.boxplot()
variazione = pd.concat([data_num, comparazione.errore_breve], axis = 1) #we recreate the complete dataset
variazione = variazione.fillna(0)
variazione

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(variazione)
scaled_df = pd.DataFrame(scaler.transform(variazione))
scaled_df.columns = variazione.columns
scaled_df.head()

X=scaled_df.iloc[:,:-1] #senza target
y=variazione['errore_breve']
from sklearn.model_selection import train_test_split

#SPLIT DATA INTO TRAIN AND TEST SET
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size =0.30, #by default is 75%-25%
                                                    random_state= 123) #fix random seed for replicability
print(X_train.shape, X_test.shape)
from sklearn.model_selection import GridSearchCV
import math

def gs_regression(model, par) :
    gs = GridSearchCV(model, par,cv=3,scoring ='neg_mean_absolute_error') 
    gs = gs.fit(X_train,y_train)
    #summarize the results of your GRIDSEARCH
    print('***GRIDSEARCH RESULTS***')
    print("Best score: %f using %s" % (gs.best_score_, gs.best_params_))
    means = gs.cv_results_['mean_test_score']
    stds = gs.cv_results_['std_test_score']
    params = gs.cv_results_['params']
    for mean, stdev, param in zip(means, stds, params):
        print("%f (%f) with: %r" % (mean, stdev, param))
    y_pred_train=gs.predict(X_train)
    y_pred_test=gs.predict(X_test)
    y_train_exp=y_train.apply(lambda x: math.exp(x)-1)
    y_test_exp=y_test.apply(lambda x: math.exp(x)-1)
    y_pred_train_exp=np.exp(y_pred_train)-1
    y_pred_test_exp=np.exp(y_pred_test)-1
    
from sklearn.ensemble import RandomForestRegressor 
regressor = RandomForestRegressor()
parameters = {}
gs_regression(regressor, parameters)
   
import seaborn as sns
sns.barplot(x=X.columns, y=forest.feature_importances_, palette="Blues_d")

variabili_importanti = X.columns[forest.feature_importances_ >= 0.03]
variabili_importanti

//analisi solamente della varizione dell'errore nel breve (come variabile bivariata)
errore_breve_num = np.zeros(100)
for i in range(0,99): 
    if variazione.errore_breve[i] >= 0:
        errore_breve_num[i] = 1
    else:
        errore_breve_num[i] = 0
        
errore_breve_num = pd.DataFrame(errore_breve_num, columns = ['errore_breve_num'])
errore_breve_num

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn import metrics 
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score

%matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt
X0 = variazione[variazione['errore_breve_num']==0]
X1 = variazione[variazione['errore_breve_num']==1]
fig, axes = plt.subplots(ncols=4, nrows=8, figsize=(20,20))
fig.tight_layout()
for i, ax in zip(range(variazione.columns.size), axes.flat):
    sns.histplot(X0.iloc[:,i], color="blue", ax=ax, stat='density', element="step",  alpha=0.3)
    sns.histplot(X1.iloc[:,i], color="red", ax=ax,stat='density', element="step",  alpha=0.3)
plt.show()




%matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt
X0 = variazione[variazione['errore_breve_num']==0]
X1 = variazione[variazione['errore_breve_num']==1]
fig, axes = plt.subplots(ncols=4, nrows=8, figsize=(20,20))
fig.tight_layout()
for i, ax in zip(range(variazione.columns.size), axes.flat):
    sns.histplot(X0.iloc[:,i], color="blue", ax=ax, stat='density', element="step",  alpha=0.3)
    sns.histplot(X1.iloc[:,i], color="red", ax=ax,stat='density', element="step",  alpha=0.3)
plt.show()

// analisi delle variabili pi√π rilevanti nella discriminazione dell'errore nel breve
X = variazione.iloc[:,1:-2]
column_names = list(X) 
y = variazione.iloc[:,-1] 
    
    
    
    













